# Кросс-валидация с методом k ближайших соседей (kNN)

Этот репозиторий содержит скрипт для применения кросс-валидации при обучении классификатора методом k ближайших соседей (kNN) при разных значениях гиперпараметра k и различном числе фолдов.

## Использование

1. Установите необходимые зависимости:

   ```bash
   pip install scikit-learn numpy

Конечно, в README.md следует подробно описать изменения, внесенные в код и результаты, которые были получены после выполнения этих изменений. Вот как можно сделать:

markdown
Copy code
# Кросс-валидация с методом k ближайших соседей (kNN)

Этот репозиторий содержит скрипт для применения кросс-валидации при обучении классификатора методом k ближайших соседей (kNN) при разных значениях гиперпараметра k и различном числе фолдов.

## Использование

1. Установите необходимые зависимости:

   ```bash
   pip install scikit-learn numpy
Запустите скрипт knn_cross_validation.py:

bash
Copy code
python knn_cross_validation.py
# Результаты
Скрипт выводит среднюю точность классификации и стандартное отклонение для каждого значения k в методе kNN при каждом варианте разбиения на фолды. Были проведены эксперименты с разными значениями числа фолдов (3, 5, 7, 10) и гиперпараметром k (3, 5, 7, 9, 11). Это позволило оценить стабильность и эффективность классификатора при различных настройках.

# Изменения
Обновлен скрипт knn_cross_validation.py, чтобы провести кросс-валидацию с разным числом фолдов и вычислить средние арифметические и стандартные отклонения для каждого варианта разбиения.
